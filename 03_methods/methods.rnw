    \lettrine{T}{his} paper primarily makes use of the free open source statistical language \R{} \citep{rcoreteam2019}. Managing the large LiDAR datasets from my personal computer was mode possible through the \texttt{lidR} \R{} package \citep{roussel2019}. Further details regarding the \R{} environment and computer setup used for this paper is given in \textbf{Appendix \ref{a:code}}. All content was written using \LaTeX{} combined with the \texttt{.rnoweb} file type \citep{ihaka2011}, for \textit{Literate Programming}\footnote{See \cite{knuth1984}}. The template is built from scratch but takes much inspiration (and code) from the \href{https://github.com/asardaes/R-LaTeX-Template}{R-LaTeX-Template}.

    All code is hosted on my personal \href{https://github.com/cjber/}{GitHub account}. Also hosted are my complete dotfiles, used in conjunction with the Linux distribution Manjaro, with the i3 window manager. All writing and code was produced using \href{https://neovim.io}{\texttt{neovim}} with my personal configuration to implement integrated development environment (IDE) style features for writing R code, while also providing essential features for writing in \LaTeX{}. \texttt{neovim} has the benefit of being both highly customisable, and lightweight, which allows for much lower system utilisation compared with R Studio when working with large datasets. One essential \texttt{vim} package to mention is the \href{https://github.com/jalvesaq/Nvim-R}{Nvim-R} vim package.

    Given in Appendix \ref{a:code} are the code snippets utilised in this methodology, for many equations, the relevant code is given as a reference to the appendix location.

\section{Data}
\label{sec:data}

<<cloud_total>>=
source("../scripts/functions.r")
ctg <- catalog("../data/point/")
number_points <- comma(sum(ctg@data$Number.of.point.records))
@

LiDAR point cloud data was downloaded through the \href{https://data.gov.uk/}{UK Government's open data repository} which uses the \href{http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/}{Open Government Licence}, allowing for:
    \begin{itemize}
        \item Copying, publishing, distributing and transmission of the data
        \item Adaptation of the data
        \item Commercial and Non-commercial use of the information
    \end{itemize}

    LiDAR data used in this paper is available \href{https://data.gov.uk/dataset/977a4ca4-1759-4f26-baa7-b566bd7ca7bf/lidar-point-cloud}{\textsc{here}} under this licence \citep{ukgovernment2019}. This data was given as a compressed LAS file format (\texttt{.laz}), the \R{} package \texttt{lidR} provided the function \texttt{catalog()} which enabled each separate \texttt{.laz} to be combined into one object of class \texttt{LAScatalog}. Analysis on this object could then be split into chunks (selected as 500m$^2$), allowing for multi-core threading to speed up analysis, and a reduction in the memory overhead when reading in data, often a limitation of the \R{} language as objects are stored entirely into memory when read \citep{wickham2014}. The \texttt{LAScatalog} object did not require the compressed \texttt{.laz} files to be read into memory as \texttt{.las} files, meaning memory limitations were far less of a problem.

    Aerial imagery was downloaded through \href{https://digimap.edina.ac.uk/}{Digimap\textsuperscript{\textregistered}
    } which uses the \textit{Aerial Digimap Educational User Licence}, allowing for free use of the data for educational purposes \citep{theuniversityofedinborough2019}.

Road centreline geometries were accessed through the \href{https://www.ordnancesurvey.co.uk/business-and-government/products/opendata.html}{Ordnance Survey Open Data repository} which shares the Open Government licence. These were downloaded in the GeoPackage format (\texttt{.gpkg}) nationally and cropped to the extent of the LiDAR point cloud data.

\section{LiDAR Preprocessing}

The total number of LiDAR points used in this study is \Sexpr{number_points}. All LIDAR data has a vertical accuracy of +/-15cm Root mean square error (RMSE). An overview of the LiDAR data selected for this study is given on Table \ref{tab:lidartab}. The variables of primary interest are:

\begin{itemize}
    \item \textbf{z:} The distance a laser pulse is reflected back to to scanner, calculated by the time taken for a return pulse to be detected.
    \item \textbf{Intensity:} The amplitude of the return pulse, reflected back by the surface terrain or objects.
	\item \textbf{ReturnNumber:} A number of range 1-5, indicating for a point, the corresponding order of a reflected laser pulse. A ReturnNumber of 1 indicates the first return for a pulse (and highest $z$ value), a return number of 5 indicates the last return (and lowest $z$ value).
	\item \textbf{NumberOfReturns:} The number of return pulses for a single laser pulse (maximum of 5).
    \item \textbf{Classification:} A number given to a point indicating a specific numeric classification. Of interest in this study is a classification of 2, indicating a ground point. More information can be found \href{http://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/lidar-point-classification.htm}{here}, which outlines numerical classifications for various vegetation types and man made structures.
\end{itemize}

<<>>=
model <- fread("/home/cjber/drive/uni/envs492/main/data/point/points.csv")
lidar_tab <- model %>% dplyr::select(Z, Intensity, ReturnNumber, NumberOfReturns, ScanDirectionFlag, EdgeOfFlightline, Classification, ScanAngleRank)
tmp <- do.call(
  data.frame,
  list(
    Mean = apply(lidar_tab, 2, mean),
    SD = apply(lidar_tab, 2, sd),
    Min = apply(lidar_tab, 2, min),
    Max = apply(lidar_tab, 2, max)
  )
)
@

<<lidartab, results='asis'>>=
make_table(tmp, cap = "LiDAR Point Cloud Summary Data")
@

\subsection{Last Pulse}

The LiDAR point cloud data used in this paper gives the values for 5 pulse returns. The canopy above roads may be excluded through ignoring early pulses (higher Z values), therefore only the last pulse values for any point are selected, this can be expressed as;

$$
\mathbf{p}_{i}=(l p x, l p y, l p z, l p i),
$$
\begin{flushright}
    \footnotesize{\ref{code:lidr_clean}}
\end{flushright}

where $\mathbf{p_i}$ is a single instance of a LiDAR point within the chosen point cloud, $lpx$ is the last pulse $x$ coordinate, $lpy$ the last pulse $y$ coordinate, $lpz$ the last pulse $z$ coordinate, and $lpi$ the last pulse intensity value.

\subsection{Normalisation}

Ground points were classified using the Cloth Simulation Filtering (CSF) algorithm, as described in \cite{zhang2016}. Points were already classified in the data provided, however, as the classification technique was unknown, reclassification was considered necessary. The general implementation simulates the movements of a piece of cloth lying over the inverse of a point cloud, as the point cloud is flipped, the cloth settles beneath ground points, while covering points that lie separate to the ground, essentially forming a digital terrain model (DTM), cloth simulations are described in more detail in \cite{bridson2005} and subsection \ref{subs:dtm}. The CSF algorithm is given;

$$
X(t+\Delta t)=2 X(t)-X(t-\Delta t)+\frac{G}{m} \Delta t^{2},
$$
\begin{flushright}
    \footnotesize{\ref{code:lidr_clean}}
\end{flushright}

where $m$  is the mass of a single LiDAR point (set to 1), $\Delta t$ is the time step between points and $G$ represents the gravity constant.

With the classification of ground points, (given $Classification = 2$), a full DTM may be produced through spatial interpolation of the classified points. This process is called normalisation, and ensures that when extracting height information, any observed values are due to objects on the surface of the terrain, and not due to the lie of the terrain itself. Interpolation uses the inverse distance weighting and $k$ nearest neighbours algorithms to produce the DTM. Nearest neighbours were selected as $k = 10$, with $p = 2$ for the inverse weighting, and used to produce a DTM with a resolution of 1m. This particular technique was selected over more comprehensive methods such as kriging as the number of points is very high, and the small benefit was considered minimal compared with the increase in computational load. The $z$ values from the DTM were then subtracted from the LiDAR point cloud, leaving a normalised point cloud.

\subsection{Points Extent}

With the normalised last pulse point cloud, the point cloud was clipped to within a 30m extent of each known road location, using the OS road shapefiles. Selecting a 30m extent ensured that even with slight inaccuracy in road location, the road LiDAR points would likely not be excluded. A large number of unimportant points were therefore removed, saving on computational resources. Additionally this extent ensured that both road and non road points were included, but reduced the chance of false positives from occurring as fewer non road points were now included in the analysis.

\begin{flushright}
    \footnotesize{\ref{code:extract_buff}}
\end{flushright}


\subsection{Noise Filtering}\label{subsec:noise}

Intensity noise was filtered through area based outlier detection, measuring the 95th percentile values within a 10m by 10m area, removing all points above the 95\% percentile. Expressed;

\[
    \begin{aligned}
\mathbf{c}_{i} = \Big(\mathbf{p}_i \in \Big[\frac{95}{100} \times \mathbf{p}_{i_{lpi}}\Big]\Big) \\
A\left(\mathbf{c}_{\mathbf{i}}\right)=10 m^{2}
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:las_filter_noise}}
\end{flushright}

where $\mathbf{c_i}$ represents a 10m$^2$ selection of LiDAR points, where each point $(\mathbf{p_i})$ has an intensity value within the 95\% percentile intensity for all points $(\mathbf{p}_{i_{lpi}})$ within $\mathbf{c_i}$.

\subsection{LiDAR Catalog}

As mentioned above, object of class LiDAR catalog enabled more efficient processing through allowing LiDAR point cloud to be processed in predefined batch sizes. Considering a collection of processed LiDAR points, with last pulse, normalised, clipped to 30m road extents, and intensity noise filtered, following noise filtering points were grouped into 500m$^2$ areas;

\[
\begin{aligned}
\mathbf{C}_{i}=\left\{\mathbf{c}_{1}, \mathbf{c}_{2}, \ldots, \mathbf{c}_{N}\right\} \\
A\left(\mathbf{C}_{\mathbf{i}}\right)=500 m^{2} \\
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:las_filter_noise}}
\end{flushright}

And each 500$m^2$ area collectively represents the overall processed point cloud;

\[
\begin{aligned}
\mathbf{S}=\left\{\mathbf{C}_{1}, \mathbf{C}_{2} \ldots, \mathbf{C}_{N}\right\}
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:comb_ctg}}
\end{flushright}

\section{Road Analysis}
\label{sec:road-extraction}

This section combines data extracted through the OS road shapefiles preprocessed LiDAR data, and aerial imagery to obtain a set of criteria to assess the chosen road network. These criteria are;


\begin{itemize}
\itemsep0em
    \item Road Width
    \item Bend Sharpness
    \item Road Steepness
    \item Surface Quality
\end{itemize}


<<>>=
roads_info <- fread("/home/cjber/drive/uni/envs492/main/data/osroads/roads_info.csv") %>% 
select(-c(geometry, length_uom, name1_lang, name2_lang))

funcs <- unique(roads_info$roadFunction)

tmp <- do.call(
  data.frame,
  list(
    Example = apply(roads_info, 2, head, 1)
  )
)
@

<<roadstab, results='asis'>>=
make_table(tmp, cap = "OS Roads Data Summary")
@

The roads in this paper consist of these functions, \Sexpr{print(funcs)}, B roads considered classified, and other functions considered unclassified. All roads and single carriageway, and so for the purpose of this analysis it is assumed they likely have the default national speed limit of 60mph. Private roads were removed, as were roads below 50m, often those clipped by the extent of the LiDAR data. As many roads did not have a name to be identified by, a column called \texttt{road\_id} was produced, corresponding to a line segment between two junctions (not necessarily a full named road).

\subsection{Road Sampling}

The LiDAR point cloud data was sampled at regular 10 meter intervals for each road, perpendicular to the road direction, ensuring that when road direction changed, the sampling locations remained perpendicular. Each road was first split into nodes at which road direction changes, and from this, points at 10 meter intervals between two connected nodes were calculated;

$$
p_k = p_1 + |p_2 - p_1| \times I_k
$$

where $I_k$ is the interval value which increases by 10 meters until the length of the total distance of the node, given $I_{1}, I_{2}, \dots, I_{k}>0$ and $k \geq 2$.

\[
\begin{aligned}
    I_k &= (L_k + 20) - T_k \\
    L_1 &= 20 \\
    T_k &= T_{k-1}  + E
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:compute_samples}}
\end{flushright}

where $L_k$ is the distance from the start of the node to the current sample line position, $T_k$ is total length of all nodes within a road from the start of the road and $E$ is the euclidean distance between two nodes.

To calculate the sample locations, perpendicular to the roads, first the $x$ and $y$ euclidean distances from a reference point $p_k$ and the end of the current node $n_2$ were calculated;

\[
\begin{aligned}
    len &= \sqrt{(n_{k+1} - p_k)} \\
    len_n &= (n / len) \times (n_{k+1} - p_k)
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:perp}}
\end{flushright}

from this, the lengths were inverted, giving two points of distance $n$ from $p_k$. Inversion was achieved by subtracting the given $len_n$ $x$ value from $p_k$, while adding the $len_n$ $y$ value, and vice versa. These perpendicular sample lines were buffered to a width of 1m, giving a total area of 20m$^2$ per sample and spatially joined to the existing LiDAR point cloud data, removing any points that fell outside the sample lines.

\begin{flushright}
    \footnotesize{\ref{code:compute_samples}}
\end{flushright}

\section{Aerial Imagery}

With the perpendicular sample lines extracted for the length of every road, to assist with the prediction of correct road locations, true colour aerial imagery was included. This imagery was first converted from three band RGB raster images, to a single-band grey-scale raster brick with values ranging 0 to 255, considered to be luminescence information.

$$
luminescence = \frac{Band_1 + Band_2 + Band_3}{3}
$$
\begin{flushright}
    \footnotesize{\ref{code:lm_compute}}
\end{flushright}

To exclude as much noise as possible from both the LiDAR point cloud intensity information, and aerial luminescence, only points with the ground classification ($Classification = 2$), and points with only a single laser return pulse were included in the models.

\subsection{Linear Probability Models}

To classify road and non-road, linear models were constructed and compared to assess effectiveness. A maximal approach was chosen, selecting all appropriate predictor variables, iterating through models by removing variables that did not significantly influence the model outcome, or created noise.

An additional variable $Dist$ was created and included, representing the shortest distance from a point to the centreline of the road it is associated with, considering that road points should be weighted more towards points that are closer to the centre-point of the road.

Linear probability models essentially follow the same formula as a linear regression model:

\[
\begin{aligned}
Y_{i}=\beta_{0}+\beta_{1}+X_{1 i}+\beta_{2} X_{2 i}+\cdots+\beta_{k} X_{k i}+u_{i}
\end{aligned}
\]

but given a binary outcome variable $Y_i$, this is considered to be a linear probability model, taking the form;

\[
\begin{aligned}
E\left(Y | X_{1}, X_{2}, \ldots, X_{k}\right)=P\left(Y=1 | X_{1}, X_{2}, \ldots, X_{3}\right)
\end{aligned}
\]

Where;

\[
\begin{aligned}
P\left(Y=1 | X_{1}, X_{2}, \ldots, X_{k}\right)=\beta_{0}+\beta_{1}+X_{1 i}+\beta_{2} X_{2 i}+\cdots+\beta_{k} X_{k i}
\end{aligned}
\]

$\beta_j$ therefore may be interpreted as the change in the probability that $Y_i = 1$, with all other predictor variable constant. $\beta_j$ may be estimated using Ordinary Least Squares regression \citep{hanck2019}. 

Likelihood values from the predictions gave a range of numerical values, points that fell below a certain threshold were removed, leaving only points that were most likely correctly identified as road points. This threshold was assess qualitatively through both observation of the distribution of probability ranges for each model, and results gained through different thresholds. Considering a threshold $x$, this may be expressed as;

\[
\begin{aligned}
\mathbf{S} &= \Big(\mathbf{p}_i \in \Big[\frac{x}{100} \times \mathbf{p}_{i_{lm}}\Big]\Big) \\
\end{aligned}
\]

Where $\mathbf{S}$ is the total point cloud.

Further qualitative assessment of the results revealed that some points considered to be noise were still present, but often isolated. To ensure no isolated points were present, the minimum distance between each point, and the nearest neighbouring point was checked, if a single point was considered isolated, with over 1m between it and any other point, it was removed.

\[
\begin{aligned}
    \mathit{D} &= \sqrt{\delta xi^{2} + \delta y^{2}} \\
    \mathbf{S} &= (\mathbf{p}_{i}\in [\mathit{D} \leq 1])
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:filter_samples}}
\end{flushright}

given $\mathit{D}$ is the minimum distance between a point and any other point.

$\mathbf{S}$ now gave of a collection of predicted road points for each sample line along a road segment, with noise removed.  To obtain road widths from these points, the maximum distance between two points in a particular sample was determined, these points were kept and all others removed. A linear section of road with two samples resembles Figure \ref{fig:sample_points};

\begin{flushright}
    \footnotesize{\ref{code:max_dist}}
\end{flushright}


\begin{figure}[htbp]
    \centering
\begin{tikzpicture}[scale=2]

\draw[-, very thick, color = gray] (0,0.5) -- (0,4);

\filldraw (-1,1) circle[radius=1pt] node [below left] {$A_1$};
\draw[-] (-1,1) -- (1,2);
\draw[dashed] (-1,1) -- node[fill=white,inner ysep=3pt, inner xsep = 3pt]{$O_A$} (1,1) ;
\draw[dotted] (1,1) -- (1,2);
\filldraw (1,2) circle[radius=1pt] node [above right] {$A_2$};

\draw(.85,1)--(.85,1.15)--(1,1.15); % right angle

\draw[-] (-.6,1) arc (0:55:.2);
\node[] at (-.5,1.12)  {$\theta_A$};

\filldraw (-1,4) circle[radius=1pt] node [below left] {$B_1$};
\draw[-] (-1,4) -- (1,3);
\draw[dashed] (-1,3) -- node[fill=white,inner ysep=3pt, inner xsep = 3pt]{$O_B$} (1,3);
\draw[dotted] (-1,3) -- (-1,4);
\filldraw (1,3) circle[radius=1pt] node [above right] {$B_2$};

\draw(-.85,3)--(-.85,3.15)--(-1,3.15); % right angle

\draw[-] (.6,3.2) arc (135:200:.2);
\node[] at (.4,3.12)  {$\theta_B$};
\end{tikzpicture}
\caption{Road LiDAR points at maximum distance apart for each sample location. Showing two example sample locations ($A$ and $B$), road centreline represented by the thick grey line. True road width is indicated by the dashed lines $O_A$ and $O_B$.}
\label{fig:sample_points}
\end{figure}

To determine the width of the road section, according to the final two selected points at every node, Pythagoras could be used to find the opposite line length, perpendicular to the road segment, considering the distance between the two points to be the hypotenuse of a right angled triangle (Figure \ref{fig:sample_points}). The average width for each road identifier was then found.

\[
\begin{aligned}
|K_1K_2| =& Hypotenuse \\
O_K =& Opposite \\
O_K =& |K_1K_2| \times cos(\theta_K)
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:opposite_length}}
\end{flushright}

\subsection{Improved Road Centrelines}

During the analysis of the linear models, it was noted that road centrelines were often inaccurate, giving road outcome values that were not representative of the road surface. In an attempt to adjust for this, road centrelines were adjusted based on the centre location of road points in each sample classified through an initial linear probability model. To find the mid point between two points $\left(x_{1}, y_{1}\right)$ and $\left(x_{2}, y_{2}\right)$ can be expressed as;

$$
\left(\frac{x_{1}+x_{2}}{2}, \frac{y_{1}+y_{2}}{2}\right)
$$
\begin{flushright}
    \footnotesize{\ref{code:mid_pts}}
\end{flushright}


With the mid point of each classified road sample, these were than joined for form new centrelines, and a further linear probability model was ran and compared, to determine the effectiveness of this technique.
\begin{flushright}
    \footnotesize{\ref{code:true_cents}}
\end{flushright}

Given the improvement in road centreline locations, it was considered feasible to construct linear probability models individually for each sample location on each road. This technique would allow for per road variation in material type or quality, and potentially reduce the amount of noise brought in from inaccurate centrelines. Preliminary testing of this method revealed that it was essential to remove any sample containing tree canopy, as given the small number of points, the predictions were based off points that misrepresented true road points. Additionally, individual linear models allowed for some filtering through $p$ values, which was not achievable through global linear models, given the very large number of points. 

\subsection{Road Angles}

The angle of bends in roads were identified through the nodes produced in the creation of the road shapefiles. First the road linestrings were split into points, with coordinates representing each node within a road, a point at which the orientation of the linestring is altered.

The bend in a road was considered to be the \textit{bearing angle} $\theta$, from a point $A\left(a_{x}, a_{y}\right)$ to a point $B\left(b_{x}, b_{y}\right)$, with the angle measured in a clockwise direction from north. This can be represented as a figure;

    \begin{figure}[htbp]
        \centering
\begin{tikzpicture}[scale=7]

\filldraw (.2,.4) circle[radius=.3pt] node [below left] {$A$};

\draw[-] (0.1,.4) -- (0.3, .4);
\draw[-] (0.2,.3) -- (0.2, .5) node[above] {$N$};

\filldraw (.8,.7) circle[radius=.3pt] node [above right] {$B$};

\draw[-] (0.2,.4) -- (0.8, .7);

    \draw[<-] (0.28,.44) arc (45:90:.111);
    \node[] at (.25,.5)  {$\theta$};
\end{tikzpicture}
\label{fig:bearingang1}
\caption{Bearing Angle Between Road Segments}
\end{figure}

To find the angle $\theta$, the point $B$ can be represented into relation to point $A$ as;

$$
\left(b_{1}, b_{2}\right)=\left(a_{1}+r \sin \theta, a_{2}+r \cos \theta\right)
$$

Where $r$ is the length of the line segment $AB$. Rearranging the equation for $\theta$ gives;

$$
    \tan \theta=\frac{b_{1}-a_{1}}{b_{2}-a_{2}}
$$

This equation can be rewritten to calculate the value of $\theta$ using the $\mathit{atan2}$ function;

$$
\hat{\theta}=\mathrm{atan} 2\left(b_{1}-a_{1}, b_{2}-a_{2}\right) \in(-\pi, \pi]
$$


Finally the bearing angle $\theta \in[0,2 \pi)$ is given as;

\[
    \begin{aligned}
\theta=\left\{\begin{array}{ll}{\hat{\theta},} & {\hat{\theta} \geq 0} \\
{2 \pi+\hat{\theta},} & {\hat{\theta}<0}\end{array}\right.
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:road_angles}}
\end{flushright}

With the bearing angle of the first line segment $AB$ for a particular road, the change in orientation of the second road segment $BC$ may be given as $\theta_{2} = \theta_{BC} - \theta_{AB}$, with additional nodes following the pattern $\theta_{k} = \theta_{N(N+1)} - \theta_{(N-1)N}$.

    \begin{figure}[htbp]
        \centering
\begin{tikzpicture}[scale=7]

\filldraw (.2,.4) circle[radius=.3pt] node [below left] {$A$};

\draw[-] (0.1,.4) -- (0.3, .4);
\draw[-] (0.2,.3) -- (0.2, .5) node[above] {$N$};

\filldraw (.8,.7) circle[radius=.3pt] node [above left] {$B$};
\filldraw (.9,1) circle[radius=.3pt] node [above right] {$C$};

\draw[-] (0.2,.4) -- (0.8, .7);
\draw[-] (0.8,.7) -- (.9, 1);

    \draw[<-] (0.28,.44) arc (45:90:.111);
    \node[] at (.25,.5)  {$\theta_{1}$};

\draw[dotted] (0.8,.7) -- (1, .8);

    \draw[<-] (0.9,.75) arc (45:90:.1);
    \node[] at (.88,.8)  {$\theta_{2}$};
\end{tikzpicture}
\caption{Bearing Angle Between two Road Segments}
\label{fig:bearingang2}
\end{figure}

For each road the maximum bearing angle between two nodes was selected, as well as the average bearing angle for a certain road.

\subsection{Road Node Elevation Change}

The elevation change between two road node points was calculated by first selecting non-normalised LiDAR points at a geometric node within a 1m$^2$ area. Nodes were obtained from the OS road data, as point coordinates obtained when the linestrings were split into points. LiDAR points were then filtered by those only classified as ground, and with only a single return, to reduce the likelihood of inaccurate $z$ values from canopy or other vegetation and vehicles. The mean $z$ value of points were found for each node, and elevation change between each node was calculated. For each road the maximum elevation change was calculated, alongside the mean elevation change.

\subsection{Surface Quality}

Surface quality was assessed roughly through the range in intensity values found in each known road point, and the average number of returns for a road for sample lines not obstructed by canopy, indicated by single returns.

\subsection{Estimate of True Widths}

QGIS used to measure roughly the width at various points along each road using 25cm resolution aerial imagery.

\section{Road Quality Assessment}

To provide a method for direct comparison between each road the extracted features are normalised and combined as one to produce the Road Quality Index (RQI). 

Normalisation of each road feature was achieved through a simple range normalisation;

\[
\begin{aligned}
m \mapsto \frac{m-r_{\min }}{r_{\max }-r_{\min }}
\end{aligned}
\]

Where $r_{\text {min }}$ denotes the minimum of the range of a variable,  $r_{\text {max }}$ denotes the maximum of the range of a variable, and $m \in\left[r_{\text {min }}, r_{\text {max }}\right]$ denotes the variable to be scaled. As an increase in road width is associated with a higher quality road, as opposed to larger values of each other variable indicating a poorer quality road, the width values were first inversed before normalisation.

Following normalisation, the sum of all normalised variables for a particular road were taken, and subtracted from 1 to give positive values indicating better quality roads, and lower values indicating lower quality roads. The value obtained from this was called the Road Quality Index.
