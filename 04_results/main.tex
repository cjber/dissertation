% TEX file generated by R with the 'knitr' package
%
% DO NOT EDIT THE TEX FILE DIRECTLY
% ===========================================================================================================

\documentclass[a4paper, notitlepage]{extreport}\usepackage[]{graphicx}\usepackage{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\input{template/preamble}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}





% ===========================================================================================================
% Cover
% ===========================================================================================================

\title{Utilising Supervised Paramatric Classification to Assess the Quality of the UK Rural Road Network using Aerial LiDAR Data}
{\copyrightfont\author{201374125}}
\date{}
    \maketitle
    \thispagestyle{empty}
    \vskip 50pt
\begin{abstract}
\centering\begin{minipage}{\dimexpr\paperwidth-10cm}
    \hrule
    \vskip 5pt
 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla consectetur turpis ut libero efficitur, ullamcorper ultrices nulla elementum. Proin enim lorem, tempus sed tempus eget, fermentum vitae odio. Aenean congue urna id metus tincidunt efficitur. Donec finibus nec elit vitae tempor. Nullam eget vestibulum arcu. Nullam pulvinar sed quam nec ullamcorper. Curabitur at faucibus augue. Nulla scelerisque pretium sodales. Nulla facilisi. In id ipsum orci. Donec ex magna, sodales quis tempus a, sollicitudin sit amet odio. Proin nec molestie ante. Fusce ut hendrerit risus. Nunc eleifend magna dui, sit amet tempus velit tincidunt et. Duis iaculis convallis mi sed scelerisque. \citep{wang2015}
    \vskip 5pt
    \hrule
    \vskip 10pt
\keywords{LiDAR; Aerial Imagery; Linear Probability Classification; Road Quality}
\end{minipage}
\end{abstract}

\vskip 12pt

{\copyrightfont\centerline{\bfseries In Partial Fulfillment of the Requirements for the Degree of}}
{\copyrightfont\centerline{\bfseries Geographic Data Science MSc}}
\centerline{\includegraphics[width = 100mm]{./template/uolLogo.png}}

% ===========================================================================================================
% Front matter
% ===========================================================================================================

\pagenumbering{Roman}

\newpage
\renewcommand{\abstractname}{Acknowledgements}
\vspace*{\fill}
\begin{abstract}
\centering\begin{minipage}{\dimexpr\paperwidth-10cm}
    \hrule
    \vskip 5pt
 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla consectetur turpis ut libero efficitur, ullamcorper ultrices nulla elementum. Proin enim lorem, tempus sed tempus eget, fermentum vitae odio. Aenean congue urna id metus tincidunt efficitur. Donec finibus nec elit vitae tempor. Nullam eget vestibulum arcu. Nullam pulvinar sed quam nec ullamcorper. Curabitur at faucibus augue. Nulla scelerisque pretium sodales. Nulla facilisi. In id ipsum orci. Donec ex magna, sodales quis tempus a, sollicitudin sit amet odio. Proin nec molestie ante. Fusce ut hendrerit risus. Nunc eleifend magna dui, sit amet tempus velit tincidunt et. Duis iaculis convallis mi sed scelerisque. \citep{wang2015}
    \vskip 5pt
    \hrule
    \vskip 10pt
\end{minipage}
\end{abstract}
\vspace*{\fill}
\thispagestyle{ack}

\tableofcontents

\listoffigures

\listoftables

% ===========================================================================================================
% Main matter
% ===========================================================================================================

\cleardoublepage
\pagenumbering{arabic}
\pagestyle{firststyle}

\chapter{Introduction}
\label{ch:introduction}

   \begin{multicols}{2}
       \lettrine{R}{oad} usage within the United Kingdom has been steadily increasing by year with the highest ever billion vehicle miles travelled in 2018 (255 million) \citep{departmentfortransport2019}. Characterised by tall hedgerows and winding turns, rural roads in the UK are often unsuited higher traffic flow, due to the obstruction of view due to the protected hedgerows, narrow lanes and often poor condition. The abundance of these roads, with "Unclassified" local network roads making up 60\% of all roads in the UK \citep{departmentfortransport2012}, and their varying nature, the national assessment of these roads into appropriate speed limits on an individual basis has been considered impractical. Due to this, there have been no individual assessments for the majority of rural roads, and given their nature are classified as unlit, single carriageway roads and thus assigned a default speed of 60mph \citep{ukgovernment2019a}. Highways England manages the motorways and trunk roads within the UK, but local road networks are maintained by Local Authorities, and as such have no comprehensive information regarding these smaller road networks \citep{highwaysengland2019}. Rural roads in the UK are often cited as by far the most dangerous road type with studies suggesting that up to two thirds of vehicle accidents occur on rural roads \citep{corben2005}.

The Rural Urban Classification defines a rural area as one outside a settlements with more than 10,000 resident population \citep{ukgovernment2011}, therefore a road could be considered rural, if either connecting or present within small settlements in the UK. this study will focus particualrly on rural connecting roads.

       A Governmental review of speed policy considered the need for the role of speed and accidents on rural roads to be further considered \citep{departmentoftheenvironmenttransportandthe2000}, suggesting a framework for individaul classification of roads, taking into account local considerations of the road to implement more suitable speed limits. In 2012, draft guidance for rural roads was presented by the Department for Transport suggesting a blanket reduction in rural single carriageway road speed limits from 60mph to 40mph including a reduction to 50mph for lower quality A and B roads \citep{bbc2012}. However, this draft guidance has yet to be implemented, and the report archived. 

       // likely due to costs involved, blanket implementation likely doesn't justify the cost. Need to rely on more quantiative analysis of individaul roads, cost estimated as \$... or cost of changing all speed cameras to metric estimated as \$80/400m. Resulting in the current state of a zombified combination of metric and british imperial meassruements.

National speed limits have seen little variation for a number of years, with the majority of roads following the broad criteria for the three main roads types. The three national speed limits are:
\begin{itemize}
\item the 30 mph speed limit on roads with street lighting (sometimes referred to as Restricted Roads)

\item the national speed limit of 60 mph on single carriageway roads

\item the national speed limit of 70 mph on dual carriageways and motorways.
\end{itemize}
\begin{flushright}
    \footnotesize{\citep{ukgovernment2019a}}
\end{flushright}

These limits are set by the UK government, however local speed limits are determined by local councils. \cite{departmentfortransport2013b} outline in Setting Local Speed Limits, that national speed limits are not appropriate for all roads, where local road conditions present the requirement for alternative speed limits. The majority of the rural road network in the UK follows the national speed limit of 60mph for single carriagway roads, and 70mpg for dual carriageway roads, despite driver speed often being far below the speed limit. Noted as especially common on C and Unclassified roads due to the narrow roads, bend, junctions and access. In 2011, an estimated 66\% of total road deaths in Britain occured on rural roads, with 51\% on single carriageway rural roads with the national speed limit of 60mph.

\cite{departmentfortransport2013b} suggest that selecting alternative speed limits for single carriageway rural roads should consider:

\begin{itemize}
    \item History of collisions
    \item The road's function
    \item Existing mean traffic speed
    \item Use by vulnerable road users
    \item The road's geometry and function
    \item The road environment, including road-side development
\end{itemize}

This paper will particualrly focus on the requirement of road geometry //

The Road Safety Management Capacity Review \citep{departmentfortransport2018} outlines the current limitations with road safety management, with the lack of defined and measureable safety performance framework, noting that such a framework should set out the long term goal of total prevention of road deaths and injuries, achevign this through a reducting in average speeds on different road types, and an improvement in emergency response times. This review states that at present there is a distinct lack of both urban and rural road hiararchies, which could be used to better match appropriate speed limits, with function, layout and design. Again, this review notes that posted speed limits often allow for speed far in excess of the design limits of single carriageway rural roads, with inappropriate but alloable speed often a contributing factor in rural accidents. Finally the report calls for a reviw on national speed limits as soon as possible.

// limitations of the newly introduced spped limit apprasial tool?

This paper will present a method for rural road extraction for a region in the North West of England. The methodology is produced in order to ensure scalability and automation, allowing for replication for any area where data is available. Data used will include road centreline geometries, LiDAR point cloud, and aerial imagery to extract road widths through linear likelihood models. Additionally, this paper aims to extract other features of roads such as elevation changes, surface quality, and the sharpness of bends. These key features aim to provide information that may inform the selection of appropriate speed limits on rural roads, where the 60mph national speed limit is inappropriate.

\section{Introduction to LiDAR}
\label{sec:overviewlidar}

\subsection{Description of LiDAR}

LiDAR data is collected by emitting rapid laser pulses from an aircraft towards the ground which are reflected back, measuring the distance between the aircraft and surface objects at up to 500,000 measurements per second \citep{environmentagency2019}. This method produces a set of highly accurate three dimensional points which collectively are known as a LiDAR point 'cloud'. As LiDAR data detects all surface objects, the resultant point cloud produced will include all natural and man made structures, including buildings, roads, trees in addition to the natural variation in the terrain height, known as a digital surface model \citep{hatger2005}.

The main features unique to LiDAR, as opposed to similar aerial data collection techniques such as true colour imagery are outlined below:

\begin{itemize}
    \item \textit{Pulses}: LiDAR systems record the data by recording emitting a laser pulse which is reflected back at the aircraft by ground objects. If the laser hits a solid object such as ground or a building roof, this laser pulse is entirely reflected back towards the aircraft, giving a single point. However, if the laser pulse hits a soft object such as a tree canopy, the pulse may be partially returned, giving multiple return pulses \citep{rottensteiner2003}. Therefore, these multiple pulse returns give information regarding objects at an exact $xy$ location, but with varying $z$ locations.

    \item \textit{Intensity}: LiDAR systems also give intensity values for return pulses, which gives information regarding the reflectance of the surface of objects that are hit by the laser pulses. If intensity is given $I$ then reflectance $R$ may be represented as $\frac{I}{E_{T}}$ where $E_T$ refers to the first pulse signal intensity \citep{charaniya2004}.

    \item \textit{Elevation:} In addition to $x$ and $y$ coordinates, the distance between the plane and the reflected ground or object is recorded and assigned a $z$ value.
\end{itemize}

\subsection{Benefits of LiDAR}

Rural roads in the UK are often characterised by dense hedgerows either side, often containing large oak trees which extend over the road surface. In addition to the reduction in corner visibility on these roads, standard aerial imagery suffers from the road surface being obscured by shadows from these trees, and the tree canopy itself. Aerial imagery also often suffers from obstruction due to clouds \citep{li2016}. Due to the inclusion of pulses with modern LiDAR data, the road surface can often be detected through the canopy by selecting the final pulse values, additionally the infrared laser pulses have smaller shadows, due to the narrow scanning angle of LiDAR \citep{shan2008}. Non LiDAR imagery often suffers from scene complexity, where road patterns, vehicles and lane markings reduce road heterogeneity \citep{li2016}.

The 3D $z$ value information provided by LiDAR data allows for the separation of ground and objects on the surface, meaning roads and buildings are often easily separated, despite having similar reflectance (or intensity) \citep{shan2008}. Additionally, the reflectance of roads is often homogeneous, and distinctly separate from vegetation \citep{clode2004}.

\subsection{Flaws with LiDAR}

LiDAR lacks any texture or spectral information, and often studies in road detection have combined LiDAR with imagery to alleviate this issue \citep{hu2004;zhu2004}, with the inclusion of luminescence information to aid with road classification \citep[e.g.][]{charaniya2004}. LiDAR points are distributed irregularly and with varying density, with point density often higher where flight strips overlap \citep{li2016}, and tall objects can occlude points, leaving limited data surrounding trees or buildings.

Often studies use LiDAR height data to identify kerbs to separate streets from pavement \citep{kumar2013;vosselman2009a}, however rural roads often have no kerb, and are at the same level as the surrounding vegetation if they are managed grass verges \citep{yadav2018}.

LiDAR data often requires a large amount of processing due to the irregular distribution of points, presence of noise and the number of variables that have to be considered, \cite{yadav2018} note that often papers do not include the computational time for processing this data, which can be time consuming.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in .local(x, ...): invalid layer names}}\end{kframe}\begin{figure}[H]

{\centering \includegraphics[width=\linewidth]{figure/area_map-1} 

}

\caption[Study are highlighting road locations]{Study are highlighting road locations}\label{fig:area_map}
\end{figure}


\end{knitrout}


\section{Objective of this paper}

\begin{itemize}
    \item Produce an automated method using LiDAR and aerial imagery to determine the true width of roads within the chosen study area.

    \item Using OS Road and LiDAR Data produce an automated method for determining the characteristic of roads that relate to overall road quality outline above.

    \item Assess the potential for speed reduction on rural roads, with the assumption that at present the roads chosen are 60mph.
\end{itemize}

\subsection{Site Selection}

The site selected in this study was chosen to include a selection of A, B, and Unclassified local roads within a rural setting. Particularly the roads chosen are often partially obscured by tree canopies and do not have visible kerbs, both key features in rural British roads.

\textbf{figure 1a}. Additionally the area selection was limited by the availability of LiDAR point cloud data, which is shown on \textbf{figure1b}.

\section{sign posting}

\end{multicols}

\chapter{Literature}
\label{ch:literature}
\input{02_literature/literature.tex}

\chapter{Methods}
\label{ch:methods}

\begin{multicols}{2}
    This paper primarily makes use of the free open source statistical language \R{} \citep{rcoreteam2019}. Managing the large LiDAR datasets from my personal computer was mode possible through the \texttt{lidR} \R{} package \citep{roussel2019}. Further details regarding the \R{} environment and computer setup used for this paper is given in \textbf{Appendix \ref{a:code}}. All content was written using \LaTeX{} combined with the \texttt{.rnoweb} file type \citep{ihaka2011}, for \textit{Literate Programming}\footnote{See \cite{knuth1984}}. The template is built from scratch but takes much inspiration (and code) from the \href{https://github.com/asardaes/R-LaTeX-Template}{R-LaTeX-Template}.

    All code is hosted on my personal \href{https://github.com/cjber/}{GitHub account}. Also hosted are my complete dotfiles, used in conjunction with the Linux distribution Manjaro, with the i3 window manager. All writing and code was produced using \href{https://neovim.io}{\texttt{neovim}} with my personal configuration to implement integrated development environment (IDE) style features for writing R code, while also providing essential features for writing in \LaTeX{}. \texttt{neovim} has the benefit of being both highly customisable, and lightweight, which allows for much lower system utilisation compared with R Studio when working with large datasets. One essential \texttt{vim} package to mention is the \href{https://github.com/jalvesaq/Nvim-R}{Nvim-R} vim package.

    Given in Appendix \ref{a:code} are the code snippets utilised in this methodology, for many equations, the relevent code is given as a reference to the appendix location.

\section{Data}
\label{sec:data}



LiDAR point cloud data was downloaded through the \href{https://data.gov.uk/}{UK Government's open data repository} which uses the \href{http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/}{Open Government Licence}, allowing for:
    \begin{itemize}
        \item Copying, publishing, distributing and transmission of the data
        \item Adaptation of the data
        \item Commercial and Non-commercial use of the information
    \end{itemize}

    LiDAR data used in this paper is available \href{https://data.gov.uk/dataset/977a4ca4-1759-4f26-baa7-b566bd7ca7bf/lidar-point-cloud}{\textsc{here}} under this licence \citep{ukgovernment2019}. This data was given as a compressed LAS file format (\texttt{.laz}), the \R{} package \texttt{lidR} provided the function \texttt{catalog()} which enabled each separate \texttt{.laz} to be combined into one object of class \texttt{LAScatalog}. Analysis on this object could then be split into chunks (selected as 500m$^2$), allowing for multi-core threading to speed up analysis, and a reduction in the memory overhead when reading in data, often a limitation of the \R{} language as objects are stored entirely into memory when read \citep{wickham2014}. The \texttt{LAScatalog} object did not require the compressed \texttt{.laz} files to be read into memory as \texttt{.las} files, meaning memory limitations were far less of a problem.

    Aerial imagery was downloaded through \href{https://digimap.edina.ac.uk/}{Digimap\textsuperscript{\textregistered}
    } which uses the \textit{Aerial Digimap Educational User Licence}, allowing for free use of the data for educational purposes \citep{theuniversityofedinborough2019}.

Road centreline geometries were accessed through the \href{https://www.ordnancesurvey.co.uk/business-and-government/products/opendata.html}{Ordnance Survey Open Data repository} which shares the Open Government licence. These were downloaded in the GeoPackage format (\texttt{.gpkg}) nationally and cropped to the extent of the LiDAR point cloud data.

\section{LiDAR Preprocessing}

The total number of LiDAR points used in this study is 9,419,272. All LIDAR data has a vertical accuracy of +/-15cm Root mean square error (RMSE). An overview of the LiDAR data selected for this study is given on Table \ref{tab:lidar}. The variables of primary interest are:

\begin{itemize}
    \item \textbf{Z:} The distance a laser pulse is reflected back to to scanner, calculated by the time taken for a return pulse to be detected.
    \item \textbf{Intensity:} The amplitude of the return pulse, reflected back by the surface terrain or objects.
	\item \textbf{ReturnNumber:} A number of range 1-5, indicating for a point, the corresponding order of a reflected laser pulse. A ReturnNumber of 1 indicates the first return for a pulse (and highest $z$ value), a return number of 5 indicates the last return (and lowest $z$ value).
	\item \textbf{NumberOfReturns:} The number of return pulses for a single laser pulse (maximum of 5).
    \item \textbf{Classification:} A number given to a point indicating a specific numeric classification. Of interest in this study is a classification of 2, indicating a ground point. More information can be found \href{http://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/lidar-point-classification.htm}{here}, which outlines numerical classifications for various vegetation types and man made structures.
\end{itemize}



\begin{table}[H]

\caption{\label{tab:lidartab}LiDAR Point Cloud Summary Data}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}{lrrrr}
\toprule
  & Mean & SD & Min & Max\\
\midrule
Z & 80.55 & 5.95 & 64.85 & 115.79\\
Intensity & 176.57 & 125.08 & 1.00 & 4064.00\\
ReturnNumber & 1.47 & 0.95 & 1.00 & 5.00\\
NumberOfReturns & 1.95 & 1.42 & 1.00 & 5.00\\
ScanDirectionFlag & 0.50 & 0.50 & 0.00 & 1.00\\
EdgeOfFlightline & 0.00 & 0.03 & 0.00 & 1.00\\
Classification & 3.04 & 1.70 & 1.00 & 8.00\\
ScanAngleRank & -1.97 & 13.18 & -22.00 & 22.00\\
\bottomrule
\end{tabular}
\end{table}





\subsection{Last Pulse}

The LiDAR point cloud data used in this paper gives the values for 5 pulse returns. The canopy above roads may be excluded through ignoring early pulses (higher Z values), therefore only the last pulse values for any point are selected, this can be expressed as;

$$
\mathbf{p}_{i}=(l p x, l p y, l p z, l p i),
$$
\begin{flushright}
    \footnotesize{\ref{code:lidr_clean}}
\end{flushright}

where $\mathbf{p_i}$ is a single instance of a LiDAR point within the chosen point cloud, $lpx$ is the last pulse $x$ coordinate, $lpy$ the last pulse $y$ coordinate, $lpz$ the last pulse $z$ coordinate, and $lpi$ the last pulse intensity value.

\subsection{Normalisation}

Ground points were classified using the Cloth Simulation Filtering (CSF) algorithm, as described in \cite{zhang2016}. Points were already classified in the data provided, however, as the classification technique was unknown, reclassification was considered necessary. The general implementation simulates the movements of a piece of cloth lying over the inverse of a point cloud, as the point cloud is flipped, the cloth settles beneath ground points, while covering points that lie separate to the ground, essentially forming a digital terrain model (DTM), cloth simulations are described in more detail in \cite{bridson2005}. The CSF algorithm is given;

$$
X(t+\Delta t)=2 X(t)-X(t-\Delta t)+\frac{G}{m} \Delta t^{2},
$$
\begin{flushright}
    \footnotesize{\ref{code:lidr_clean}}
\end{flushright}

where $m$  is the mass of a single LiDAR point (set to 1), $\Delta t$ is the time step between points and $G$ represents the gravity constant.

With the classification of ground points, (given $Classification = 2$), a full DTM may be produced through spatial interpolation of the classified points. This process is called normalisation, and ensures that when extracting height information, any observed values are due to objects on the surface of the terrain, and not due to the lie of the terrain itself. Interpolation uses the inverse distance weighting and $k$ nearest neighbours algorithms to produce the DTM. Nearest neighbours were selected as $k = 10$, with $p = 2$ for the inverse weighting, and used to produce a DTM with a resolution of 1m. This particular technique was selected over more comprehensive methods such as kriging as the number of points is very high, and the small benefit was considered minimal compared with the increase in computational load. The $z$ values from the DTM were then subtracted from the LiDAR point cloud, leaving a normalised point cloud.

\subsection{Points Extent}

With the normalised last pulse point cloud, the point cloud was clipped to within a 30m extent of each known road location, using the OS road shapefiles. Selecting a 30m extent ensured that even with slight inaccuracy in road location, the road LiDAR points would likely not be excluded. A large number of unimportant points were therefore removed, saving on computational resources. Additionally this extent ensured that both road and non road points were included, but reduced the chance of false positives from occuring as fewer non road points were now included in the analysis.

\section{Road Analysis}
\label{sec:road-extraction}

This section combines data extracted through the OS road shapefiles preprocessed LiDAR data, and aerial imagery to obtain a set of creteria to assess the chosen road network. These criteria are;

\begin{itemize}
\itemsep0em
    \item Road Width
    \item Bend Sharpness
    \item Road Steepness
    \item Surface Quality
\end{itemize}




\begin{table}[H]

\caption{\label{tab:roadstab}OS Roads Data Summary}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}{l>{\raggedright\arraybackslash}p{15em}}
\toprule
id & idE381337E-E88D-4232-8CAD-F543F178EBE4\\
endNode & id42B6F387-D838-445C-AA7A-6558362B7B9F\\
startNode & idC8EE8B4C-D965-436A-BA02-A0925A6EA1B8\\
roadNumberTOID & osgb4000000013398492\\
roadNameTOID & \\
fictitious & FALSE\\
roadClassification & B Road\\
roadFunction & B Road\\
formOfWay & Single Carriageway\\
length & 241\\
loop & FALSE\\
primaryRoute & FALSE\\
trunkRoad & FALSE\\
roadClassificationNumber & B5392\\
name1 & \\
name2 & \\
roadStructure & \\
\bottomrule
\end{tabular}
\end{table}



\subsection{Road Sampling}

The LiDAR point cloud data was sampled at regular 10 meter intervals for each road, perpendicular to the road direction, ensuring that when road directin changed, the sampling locations remained perpendicular. Each road was first split into nodes at which road direction changes, and from this, points at 10 meter intervals between two connected nodes were calculated;
$$
p_k = p_1 + |p_2 - p_1| \times I_k
$$

where $I_k$ is the interval value which increases by 10 meters until the length of the total distance of the node, given $I_{1}, I_{2}, \dots, I_{k}>0 and k \geq 2$.

\[
\begin{aligned}
    I_k &= (L_k + 20) - T_k \\
    L_1 &= 20 \\
    T_k &= T_{k-1}  + E
\end{aligned}
\]

where $L_k$ is the distance from the start of the node to the current sample line position, $T_k$ is total length of all nodes within a road from the start of the road and $E$ is the euclidean distance between two nodes.

To calculate the sample locations, perpendicular to the roads, first the $x$ and $y$ euclidean distances from a reference point $p_k$ and the end of the current node $n_2$ were calculated;

\[
\begin{aligned}
    len &= \sqrt{(n_{k+1} - p_k)} \\
    len_n &= (n / len) \times (n_{k+1} - p_k)
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:perp}}
\end{flushright}

from this, the lengths were inverted, giving two points of distance $n$ from $p_k$. Inversion was achieved by subtracting the given $len_n$ $x$ value from $p_k$, while adding the $len_n$ $y$ value, and vice versa. These perpendicular sample lines were buffered to a width of 1m, giving a total area of 20m$^2$ per sample and spatially joined to the existing LiDAR point cloud data, removing any points that fell outside the sample lines.

\begin{flushright}
    \footnotesize{\ref{code:compute_samples}}
\end{flushright}

\section{Aerial Imagery}

With the perpendicular sample lines extracted for the length of every road, to assist with the prediction of correct road locations, true colour aerial imagery was included. This imagery was first converted from three band RGB raster images, to a single-band grey-scale raster brick with values ranging 0 to 255, considered to be luminescence information.

$$
    luminescence = (Band_1 + Band_2 + Band_3) \div 3
$$
\begin{flushright}
    \footnotesize{\ref{code:lm_compute}}
\end{flushright}

To exclude as much noise as possible from both the LiDAR point cloud intensity information, and aerial luminescence, only points with the ground classification ($Classification = 2$), and points with only a single laser return pulse were included in the models ($NumberOfReturns = 1$).

\subsection{Linear Probability Model}

Individual linear probability models were constructed for each sample location for each road, giving results for a cluster of points across a perpendicular segment of each road every 20m. Road centrelines were selected as the outcome variable, provided by the OS road network line shapefiles, buffered to 1m to ensure a three dimensional cross section of points. Additionally, global linear probability models were constructed, and compared against the individual linear models.

Models were constructed using a maximal approach, selecting all appropriate predictor variables, iterating through models by removing variables that did not significantly influence the model outcome, or created noise.

An additional variable $Dist$ was included, representing the shortest distance from a point to the centreline of the road it is associated with, considering that road points should be weighted more towards points that are closer to the centre-point of the road.

Predictions for each point were then ran using each model, which gave the likelihood a point was either road or non road. As the likelihood values from the predictions gave a range of numerical values, points that fell below a certain threshold were removed, leaving only points that were most likely correctly identified as road points. This threshold was selected as the $95\%$ quantile for each sample point;

\[
\begin{aligned}
\mathbf{S} &= \Big(\mathbf{p}_i \in \Big[\frac{95}{100} \times \mathbf{p}_{i_{lpi}}\Big]\Big) \\
\end{aligned}
\]

Where $\mathbf{S}$ is the total point cloud.

Some points considered to be noise were still present, but often isolated. To ensure no isolated points were present, the time interval between two neighbouring points was checked, if a large time interval was found, the isolated point was removed.

$\mathbf{S}_i$ now consisted of a collection of predicted road points for each sample line along a road segment, excluding sample lines partially or fully obscured by tree canopy. To obtain road widths from these points, the maximum distance between two points in a particular sample was determined, these points were kept and all others removed. A linear section of road with two samples resembles \ref{fig:sample_points};

\begin{center}
\begin{tikzpicture}[scale=2]

\draw[-, very thick, color = gray] (0,0.5) -- (0,4);

\filldraw (-1,1) circle[radius=1pt] node [below left] {$A_1$};
\draw[-] (-1,1) -- (1,2);
\draw[dashed] (-1,1) -- node[fill=white,inner ysep=3pt, inner xsep = 3pt]{$O_A$} (1,1) ;
\draw[dotted] (1,1) -- (1,2);
\filldraw (1,2) circle[radius=1pt] node [above right] {$A_2$};

\draw(.85,1)--(.85,1.15)--(1,1.15); % right angle

\draw[<-] (-.6,1) arc (0:55:.2);
\node[] at (-.5,1.12)  {$\theta_A$};

\filldraw (-1,4) circle[radius=1pt] node [below left] {$B_1$};
\draw[-] (-1,4) -- (1,3);
\draw[dashed] (-1,3) -- node[fill=white,inner ysep=3pt, inner xsep = 3pt]{$O_B$} (1,3);
\draw[dotted] (-1,3) -- (-1,4);
\filldraw (1,3) circle[radius=1pt] node [above right] {$B_2$};

\draw(-.85,3)--(-.85,3.15)--(-1,3.15); % right angle

\draw[->] (.6,3.2) arc (135:200:.2);
\node[] at (.4,3.12)  {$\theta_B$};

\end{tikzpicture}
\end{center}
\captionof{figure}{Road LiDAR points at maximum distance apart for each sample location. Showing two example sample locations ($A$ and $B$), road centreline represented by the thick grey line. True road width is indicated by the dashed lines $O_A$ and $O_B$.}



To determine the width of the road section, according to the final two selected points at every node, pythagoras could be used to find the opposite line length, perpendicular to the road segement, considering the distance between the two points to be the hypoenuse of a right angled triangle (\ref{fig:sample_points}). The averge width for each road identifier was then found.

$|K_1K_2| = Hypotenuse$, $O_K = Opposite$, therefore $O_K = |K_1K_2| \times cos(\theta_K)$

\section{Road Angles}

The angle of bends in roads were identified through the nodes produced in the creation of the road shapefiles. First the road linestrings were split into points, with coordinates representing each node within a road, a point at which the orientation of the linestring is altered.

The bend in a road was considered to be the \textit{bearing angle} $\theta$, from a point $A\left(a_{x}, a_{y}\right)$ to a point $B\left(b_{x}, b_{y}\right)$, with the angle measured in a clockwise direction from north. This can be represented as a figure;

\begin{center}
\begin{tikzpicture}[scale=7]

\filldraw (.2,.4) circle[radius=.3pt] node [below left] {$A$};

\draw[-] (0.1,.4) -- (0.3, .4);
\draw[-] (0.2,.3) -- (0.2, .5) node[above] {$N$};

\filldraw (.8,.7) circle[radius=.3pt] node [above right] {$B$};

\draw[-] (0.2,.4) -- (0.8, .7);

    \draw[<-] (0.28,.44) arc (45:90:.111);
    \node[] at (.25,.5)  {$\theta$};
\end{tikzpicture}
\end{center}
\captionof{figure}{Bearing Angle Between Road Segments}

To find the angle $\theta$, the point $B$ can be represented into relation to point $A$ as;

$$
\left(b_{1}, b_{2}\right)=\left(a_{1}+r \sin \theta, a_{2}+r \cos \theta\right)
$$

Where $r$ is the length of the line segment $AB$. Rearranging the equation for $\theta$ gives;

$$
    \tan \theta=\frac{b_{1}-a_{1}}{b_{2}-a_{2}}
$$

This equation can be rewritten to calculate the value of $\theta$ using the $\mathit{atan2}$ function;

$$
\hat{\theta}=\mathrm{atan} 2\left(b_{1}-a_{1}, b_{2}-a_{2}\right) \in(-\pi, \pi]
$$


Finally the bearing angle $\theta \in[0,2 \pi)$ is given as;

\[
    \begin{aligned}
\theta=\left\{\begin{array}{ll}{\hat{\theta},} & {\hat{\theta} \geq 0} \\
{2 \pi+\hat{\theta},} & {\hat{\theta}<0}\end{array}\right.
\end{aligned}
\]
\begin{flushright}
    \footnotesize{\ref{code:angles}}
\end{flushright}

With the bearing angle of the first line segment $AB$ for a particular road, the change in orientation of the second road segment $BC$ may be given as $\theta_{2} = \theta_{BC} - \theta_{AB}$, with additional nodes following the pattern $\theta_{k} = \theta_{N(N+1)} - \theta_{(N-1)N}$.

\begin{center}
\begin{tikzpicture}[scale=7]

\filldraw (.2,.4) circle[radius=.3pt] node [below left] {$A$};

\draw[-] (0.1,.4) -- (0.3, .4);
\draw[-] (0.2,.3) -- (0.2, .5) node[above] {$N$};

\filldraw (.8,.7) circle[radius=.3pt] node [above left] {$B$};
\filldraw (.9,1) circle[radius=.3pt] node [above right] {$C$};

\draw[-] (0.2,.4) -- (0.8, .7);
\draw[-] (0.8,.7) -- (.9, 1);

    \draw[<-] (0.28,.44) arc (45:90:.111);
    \node[] at (.25,.5)  {$\theta_{1}$};

\draw[dotted] (0.8,.7) -- (1, .8);

    \draw[<-] (0.9,.75) arc (45:90:.1);
    \node[] at (.88,.8)  {$\theta_{2}$};
\end{tikzpicture}
\end{center}
\captionof{figure}{Bearing Angle Between two Road Segments}

For each road the maximum bearing angle between two nodes was selected, as well as the average bearing angle for a certain road.

\subsection{Road Node Elevation Change}

The elevation change between two road node points was calculated by first selecting non-normalised LiDAR points at a node points within a 1m$^2$ area. Points were then filtered by those only classified as ground, and with only a single return, to reduce the chance of inaccurate $z$ values. With several filtered points for each node, the mean $z$ value was found for each node, and elevation change between each node was calculated. For each road the maximum elevation change was calculated, alongside the mean elevation change.

\subsection{Surface Quality}

Surface quality was assessed roughly through the range in intensity values found in each known road point, and the average number of returns for a road.

\end{multicols}

\chapter{Results}
\label{ch:results}

\begin{multicols}{2}

\section{Overview of LiDAR Data}

Table \ref{tab:lidar} indicates that there are likely some points with noise, particularly reflected by the highest intensity value (4063) relative to the mean value (187). Noise exclusion techniques are described in \cite{fang2004}, this paper takes a simplistic noise filtering technique that aims to solely remove extreme outliers from the observed intensity values in the chosen data.

\section{Overview of Roads}

Class differences, all singlecarriageway roads, therefore likely 60mph. Removed private roads. A roads + B roads + unclassified. Many unnamed roads, only identification possible through \texttt{identifier}, which splits roads by junctions.

Histograms?

\section{Data Preperation}

Covers script 00.



from \ref{fig:fig_buff} \textbf{(b)} intensities values for ground points below the tree are much lower than those that are not below trees, essentially if including returns with higher than 1 return the intensity values are more unreliable.

// find Average intensity values for first and last returns, i.e. show the shadow below trees


\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}[H]

{\centering \subfloat[Base point cloud $Z$ values\label{fig:fig_lp1}]{\includegraphics[width=\linewidth]{figure/fig_lp-1} }
\subfloat[Normalised Point cloud $Z$ values for only last returns ($lpz$)\label{fig:fig_lp2}]{\includegraphics[width=\linewidth]{figure/fig_lp-2} }
\subfloat[Aerial Data combined to 1 band\label{fig:fig_lp3}]{\includegraphics[width=\linewidth]{figure/fig_lp-3} }
\subfloat[Base point cloud $Z$ values\label{fig:fig_lp4}]{\includegraphics[width=\linewidth]{figure/fig_lp-4} }

}

\caption[LiDAR point clouds for one selected road section aggregated into 1m$^2$ grids]{LiDAR point clouds for one selected road section aggregated into 1m$^2$ grids}\label{fig:fig_lp}
\end{figure}


\end{knitrout}

\section{Perpendicular Sampling}

Covers 01

Show figure of sample lines. Show the reduction in number of points (memory saving)

\section{Linear Probability Model}

Covers 02

\section{Widths and Road Quality}

\section{Road Assessment}


\begin{table}[H]

\caption{\label{tab:cor_table}Correlation Matrix}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}{lllll}
\toprule
Variable & Width & Max Angle & Max Z & Int Range\\
\midrule
Width &  & -0.03 & 0.14 & -0.08\\
Max Angle & -0.03 &  & 0.60 ** & 0.36\\
Max Z & 0.14 & 0.60 ** &  & 0.57 *\\
Int Range & -0.08 & 0.36 & 0.57 * & \\
\bottomrule
\multicolumn{5}{l}{\textit{ }}\\
\multicolumn{5}{l}{*** Significant at the 0.001 level}\\
\multicolumn{5}{l}{** Significant at the 0.005 level}\\
\multicolumn{5}{l}{* Significant as the 0.01 level}\\
\end{tabular}
\end{table}



\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\linewidth]{figure/unnamed-chunk-9-1} 

}



\end{knitrout}

\section(Linear Probability Model)

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
Reading layer `roads_line' from data source `/home/cjber/drive/uni/envs492/main/data/derived/roads/roads_line.gpkg' using driver `GPKG'
Simple feature collection with 41 features and 2 fields
geometry type:  LINESTRING
dimension:      XY
bbox:           xmin: 380000 ymin: 368000 xmax: 382000 ymax: 370000
epsg (SRID):    NA
proj4string:    +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs
Reading layer `roads_line' from data source `/home/cjber/drive/uni/envs492/main/data/derived/roads/roads_line.gpkg' using driver `GPKG'
Simple feature collection with 41 features and 2 fields
geometry type:  LINESTRING
dimension:      XY
bbox:           xmin: 380000 ymin: 368000 xmax: 382000 ymax: 370000
epsg (SRID):    NA
proj4string:    +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs
[1] 0.9469083
[1] 0.9464282
[1] 0.957181
[1] 0.9579088
[1] 0.9583517
\end{verbatim}
\end{kframe}
\end{knitrout}


First model (maximal):

//NOTES//
1. Unfiltered vs filtered global maximal model.. Filters include no samples with multiple returns (partial canopy obstruction). excludes far toomany points

2. Compare global models 1/2/3, and generalised linear model using f1.

3. Compare global model 1 (best fit), to individual model using f1.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\linewidth]{figure/lm_figs-1} 

}




{\centering \includegraphics[width=\linewidth]{figure/lm_figs-2} 

}



\end{knitrout}


\begin{equation}
\begin{aligned}
\mathrm{Road}_{t} = \alpha 
    &+ \beta_{1}  \mathrm{Intensity}_{t} \\
    &+ \beta_{2}  \mathrm{Luminescence}_{t}    \\
    &+ \beta_{3}  \mathrm{Z}_{t} \\
    &+ \beta_{4}  \mathrm{Dist}_{t} + \epsilon
\end{aligned}
\end{equation}

//for this section see 450 assess2, details on validation etc.

\section{Noise Filtering}


\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
Reading layer `sample_lines' from data source `/home/cjber/drive/uni/envs492/main/data/derived/roads/sample_lines.gpkg' using driver `GPKG'
Simple feature collection with 610 features and 2 fields
geometry type:  POLYGON
dimension:      XY
bbox:           xmin: 380012.1 ymin: 367979.7 xmax: 382020.7 ymax: 370022.1
epsg (SRID):    NA
proj4string:    +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs
\end{verbatim}
\end{kframe}

{\centering \includegraphics[width=\linewidth]{figure/unnamed-chunk-11-1} 

}



\end{knitrout}

// Manually measure a road width for a reference, i.e. how close to accurate different models are. GLM LM and individual filtered and unfiltered. Find max and min widths and mean, describe what likely causes the differences.

\section{Further Analysis}

// if there is time:

Use width and max bend sharpness to estimate required speed for required stopping distance. Some maths could be involved. Use to produce speed limit assessment, include steepness somehow (speed limits due to stwwpwnss etc)


\end{multicols}

\chapter{Discussion}
\label{ch:discussion}

\begin{multicols}{2}
=== notes ===
\citep{hatger2005}
The idea now is to use this information in a more sensitive
segmentation, trying to extract the true road extents.
Of course, when there is no C0 (height) or C1 (inclination)
discontinuity at the road boundaries, there is no way de-
tecting it using laser scan data, and other data sources such
as aerial images have to be used. However, the question
is how reliable even small discontinuities can be detected.
For example, a road may be bounded by an embankment,
which usually is a relatively large structure. It may on the
other hand be separated from the pavement or a traffic is-
land by a kerb of only 15 cm in height. This seems to
be hopeless, since it is close to the expected noise of the
laser measurement. However, if one considers profiles per-
pendicular to the road, the point is that a 10 m wide road,
scanned with 1 m density, will yield 10 measurements to
estimate the road surface (assumed to be planar), leading
to a standard deviation of about 15 cm /
10  5 cm.


// Mention logistic regression, considered but not used as results not better and requries a payoff.
\end{multicols}

% ===========================================================================================================
% Bibliography
% ===========================================================================================================

\bibliographystyle{agsm}
\linespread{1}

\bibliography{kbib}

\begin{center}
% remember to compile twice for current word count
Word Count: 3585

\end{center}

\thispagestyle{newchapter}
\cleardoublepage

% ===========================================================================================================
% Appendices
% ===========================================================================================================
\appendix

\chapter{Code Appendix}
\label{a:code}

\section{Session Information}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Manjaro Linux

Matrix products: default
BLAS:   /usr/lib/libopenblasp-r0.3.6.so
LAPACK: /usr/lib/liblapack.so.3.8.0

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   
 [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] pbapply_1.4-1              rgdal_1.4-4               
 [3] future_1.14.0              varhandle_2.0.3           
 [5] forcats_0.4.0              stringr_1.4.0             
 [7] dplyr_0.8.3                purrr_0.3.2               
 [9] readr_1.3.1                tidyr_0.8.3               
[11] tibble_2.1.3               tidyverse_1.2.1           
[13] knitr_1.24                 lidR_2.1.2                
[15] raster_2.9-23              sp_1.3-1                  
[17] scales_1.0.0               kableExtra_1.1.0          
[19] data.table_1.12.2          sf_0.7-7                  
[21] ggpubr_0.2.2               magrittr_1.5              
[23] cowplot_1.0.0              viridis_0.5.1             
[25] viridisLite_0.3.0          broom_0.5.2               
[27] ggthemes_4.2.0             RStoolbox_0.2.6           
[29] PerformanceAnalytics_1.5.3 xts_0.11-2                
[31] zoo_1.8-6                  Hmisc_4.2-0               
[33] ggplot2_3.2.0              Formula_1.2-3             
[35] survival_2.44-1.1          lattice_0.20-38           
[37] pacman_0.5.1               nvimcom_0.9-83            
[39] colorout_1.2-1            

loaded via a namespace (and not attached):
 [1] colorspace_1.4-1    ggsignif_0.6.0      class_7.3-15       
 [4] htmlTable_1.13.1    base64enc_0.1-3     rstudioapi_0.10    
 [7] listenv_0.7.0       rlas_1.3.2          prodlim_2018.04.18 
[10] lubridate_1.7.4     xml2_1.2.1          codetools_0.2-16   
[13] splines_3.6.1       doParallel_1.0.15   zeallot_0.1.0      
[16] jsonlite_1.6        caret_6.0-84        cluster_2.1.0      
[19] rgeos_0.5-1         compiler_3.6.1      httr_1.4.1         
[22] backports_1.1.4     assertthat_0.2.1    Matrix_1.2-17      
[25] lazyeval_0.2.2      cli_1.1.0           prettyunits_1.0.2  
[28] acepack_1.4.1       htmltools_0.3.6     tools_3.6.1        
[31] gtable_0.3.0        glue_1.3.1          reshape2_1.4.3     
[34] Rcpp_1.0.2          RCSF_1.0.1          cellranger_1.1.0   
[37] vctrs_0.2.0         nlme_3.1-140        iterators_1.0.12   
[40] timeDate_3043.102   gower_0.2.1         xfun_0.8           
[43] globals_0.12.4      rvest_0.3.4         XML_3.98-1.20      
[46] MASS_7.3-51.4       ipred_0.9-9         hms_0.5.0          
[49] parallel_3.6.1      RColorBrewer_1.1-2  geosphere_1.5-10   
[52] gridExtra_2.3       rpart_4.1-15        latticeExtra_0.6-28
[55] stringi_1.4.3       highr_0.8           foreach_1.4.7      
[58] e1071_1.7-2         checkmate_1.9.4     lava_1.6.6         
[61] rlang_0.4.0         pkgconfig_2.0.2     evaluate_0.14      
[64] labeling_0.3        recipes_0.1.6       htmlwidgets_1.3    
[67] tidyselect_0.2.5    plyr_1.8.4          R6_2.4.0           
[70] generics_0.0.2      DBI_1.0.0           pillar_1.4.2       
[73] haven_2.1.1         foreign_0.8-71      withr_2.1.2        
[76] units_0.6-3         nnet_7.3-12         modelr_0.1.5       
[79] crayon_1.3.4        KernSmooth_2.23-15  rmarkdown_1.14     
[82] progress_1.2.2      grid_3.6.1          readxl_1.3.1       
[85] ModelMetrics_1.2.2  digest_0.6.20       classInt_0.4-1     
[88] webshot_0.5.1       stats4_3.6.1        munsell_0.5.0      
[91] quadprog_1.5-7     
\end{verbatim}
\end{kframe}
\end{knitrout}
\newpage

\section{Functions}

\subsection{Formatting} \label{code:make_table}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{make_table} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{df}\hlstd{,} \hlkwc{cap}\hlstd{,} \hlkwc{dig} \hlstd{=} \hlnum{2}\hlstd{) \{}
    \hlkwd{require}\hlstd{(kableExtra)}
    \hlkwd{require}\hlstd{(tidyverse)}

    \hlkwd{options}\hlstd{(}\hlkwc{knitr.kable.NA} \hlstd{=} \hlstr{""}\hlstd{)}
    \hlkwd{kable}\hlstd{(df,}
        \hlkwc{digits} \hlstd{= dig,} \hlkwc{caption} \hlstd{= cap,}
        \hlkwc{linesep} \hlstd{=} \hlstr{""}\hlstd{,}
        \hlkwc{longtable} \hlstd{=} \hlnum{FALSE}\hlstd{,} \hlkwc{booktabs} \hlstd{=} \hlnum{TRUE}\hlstd{,}
        \hlkwc{format} \hlstd{=} \hlstr{"latex"}\hlstd{,}
        \hlkwc{escape} \hlstd{= F}
    \hlstd{)} \hlopt{%>%}
        \hlkwd{kable_styling}\hlstd{(}\hlkwc{font_size} \hlstd{=} \hlnum{8}\hlstd{)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
\subsection{Catalog to Dataframe} \label{code:ctg_to_df}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{ctg_to_df} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{cluster}\hlstd{) \{}
    \hlstd{las} \hlkwb{<-} \hlkwd{readLAS}\hlstd{(cluster)}
    \hlkwa{if} \hlstd{(}\hlkwd{is.empty}\hlstd{(las)) \{}
        \hlkwd{return}\hlstd{(}\hlkwa{NULL}\hlstd{)}
    \hlstd{\}}
    \hlstd{las} \hlkwb{<-} \hlkwd{as.spatial}\hlstd{(las)}
    \hlstd{las} \hlkwb{<-} \hlkwd{as.data.frame}\hlstd{(las)}
    \hlkwd{return}\hlstd{(las)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{LiDAR Clean} \label{code:lidr_clean}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lidr_clean} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{cluster}\hlstd{) \{}
    \hlstd{las} \hlkwb{<-} \hlkwd{readLAS}\hlstd{(cluster)}
    \hlkwa{if} \hlstd{(}\hlkwd{is.empty}\hlstd{(las)) \{}
        \hlkwd{return}\hlstd{(}\hlkwa{NULL}\hlstd{)}
    \hlstd{\}}
    \hlkwd{epsg}\hlstd{(las)} \hlkwb{<-} \hlnum{27700}
    \hlcom{# remove all but last return}
    \hlstd{las} \hlkwb{<-} \hlkwd{lasfilter}\hlstd{(las, NumberOfReturns} \hlopt{==} \hlstd{ReturnNumber)}

    \hlcom{# find ground points}
    \hlstd{las} \hlkwb{<-} \hlkwd{lasground}\hlstd{(las,} \hlkwd{csf}\hlstd{())}

    \hlcom{## Create Point DEM}
    \hlcom{# interpolate ground points to create raster dtm. Uses Classification = 2}
    \hlcom{# very large number of points, therefore idw used as opposed to kriging}
    \hlstd{dtm} \hlkwb{<-} \hlkwd{grid_terrain}\hlstd{(las,} \hlnum{1}\hlstd{,} \hlkwd{knnidw}\hlstd{(}\hlkwc{k} \hlstd{=} \hlnum{10}\hlstd{,} \hlkwc{p} \hlstd{=} \hlnum{2}\hlstd{))}
    \hlcom{# normalise heights using dtm}
    \hlstd{las} \hlkwb{<-} \hlkwd{lasnormalize}\hlstd{(las, dtm)}
    \hlkwd{return}\hlstd{(las)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Filter Noise} \label{code:filter_noise}


\subsection{Extract Buffer} \label{code:extract_buff}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{extract_buff} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{cluster}\hlstd{,} \hlkwc{clip_input}\hlstd{) \{}
    \hlstd{las} \hlkwb{<-} \hlkwd{readLAS}\hlstd{(cluster)}

    \hlkwa{if} \hlstd{(}\hlkwd{is.empty}\hlstd{(las)) \{}
        \hlkwd{return}\hlstd{(}\hlkwa{NULL}\hlstd{)}
    \hlstd{\}}

    \hlkwa{if} \hlstd{(}\hlopt{!}\hlkwd{is.null}\hlstd{(clip_input)) \{}
        \hlstd{las} \hlkwb{<-} \hlkwd{lasclip}\hlstd{(las, clip_input)}

        \hlkwa{if} \hlstd{(}\hlkwd{length}\hlstd{(las)} \hlopt{>} \hlnum{1}\hlstd{) \{}
            \hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlkwd{length}\hlstd{(las)) \{}
                \hlkwa{if} \hlstd{(}\hlopt{!}\hlkwd{is.empty}\hlstd{(las[[i]])) \{}
                    \hlstd{las} \hlkwb{<-} \hlkwd{do.call}\hlstd{(rbind, las)}
                    \hlkwd{return}\hlstd{(las)}
                \hlstd{\}}
            \hlstd{\}}
        \hlstd{\}}
    \hlstd{\}}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Euclidean Distance} \label{code:euc}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Function to calculate Euclidean distance between 2 points}
\hlstd{euclidean_distance} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{p1}\hlstd{,} \hlkwc{p2}\hlstd{) \{}
    \hlkwd{return}\hlstd{(}\hlkwd{sqrt}\hlstd{((p2[}\hlnum{1}\hlstd{]} \hlopt{-} \hlstd{p1[}\hlnum{1}\hlstd{])}\hlopt{**}\hlnum{2} \hlopt{+} \hlstd{(p2[}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{p1[}\hlnum{2}\hlstd{])}\hlopt{**}\hlnum{2}\hlstd{))}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Perpendicular Sampling} \label{code:perp}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Function to calculate 2 points on a line perpendicular to another defined by 2 points p1,p2}
\hlcom{# For point at interval, which can be a proportion of the segment length, or a constant}
\hlcom{# At distance n from the source line}
\hlstd{calc_perp} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{p1}\hlstd{,} \hlkwc{p2}\hlstd{,} \hlkwc{n}\hlstd{,} \hlkwc{interval} \hlstd{=} \hlnum{0.5}\hlstd{,} \hlkwc{proportion} \hlstd{=} \hlnum{TRUE}\hlstd{) \{}
    \hlcom{# Calculate x and y distances}
    \hlstd{x_len} \hlkwb{<-} \hlstd{p2[}\hlnum{1}\hlstd{]} \hlopt{-} \hlstd{p1[}\hlnum{1}\hlstd{]}
    \hlstd{y_len} \hlkwb{<-} \hlstd{p2[}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{p1[}\hlnum{2}\hlstd{]}

    \hlcom{# If proportion calculate reference point from tot_length}
    \hlkwa{if} \hlstd{(proportion) \{}
        \hlstd{point} \hlkwb{<-} \hlkwd{c}\hlstd{(p1[}\hlnum{1}\hlstd{]} \hlopt{+} \hlstd{x_len} \hlopt{*} \hlstd{interval, p1[}\hlnum{2}\hlstd{]} \hlopt{+} \hlstd{y_len} \hlopt{*} \hlstd{interval)}
    \hlstd{\}}
    \hlcom{# Else use the constant value}
    \hlkwa{else} \hlstd{\{}
        \hlstd{tot_len} \hlkwb{<-} \hlkwd{euclidean_distance}\hlstd{(p1, p2)}
        \hlstd{point} \hlkwb{<-} \hlkwd{c}\hlstd{(}
            \hlstd{p1[}\hlnum{1}\hlstd{]} \hlopt{+} \hlstd{x_len} \hlopt{/} \hlstd{tot_len} \hlopt{*} \hlstd{interval,}
            \hlstd{p1[}\hlnum{2}\hlstd{]} \hlopt{+} \hlstd{y_len} \hlopt{/} \hlstd{tot_len} \hlopt{*} \hlstd{interval}
        \hlstd{)}
    \hlstd{\}}

    \hlcom{# Calculate the x and y distances from reference point}
    \hlcom{# to point on line n distance away}
    \hlstd{ref_len} \hlkwb{<-} \hlkwd{euclidean_distance}\hlstd{(point, p2)}
    \hlstd{xn_len} \hlkwb{<-} \hlstd{(n} \hlopt{/} \hlstd{ref_len)} \hlopt{*} \hlstd{(p2[}\hlnum{1}\hlstd{]} \hlopt{-} \hlstd{point[}\hlnum{1}\hlstd{])}
    \hlstd{yn_len} \hlkwb{<-} \hlstd{(n} \hlopt{/} \hlstd{ref_len)} \hlopt{*} \hlstd{(p2[}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{point[}\hlnum{2}\hlstd{])}

    \hlcom{# Invert the x and y lengths and add/subtract from the refrence point}
    \hlstd{ref_points} \hlkwb{<-} \hlkwd{rbind}\hlstd{(}
        \hlstd{point,}
        \hlkwd{c}\hlstd{(point[}\hlnum{1}\hlstd{]} \hlopt{+} \hlstd{yn_len, point[}\hlnum{2}\hlstd{]} \hlopt{-} \hlstd{xn_len),}
        \hlkwd{c}\hlstd{(point[}\hlnum{1}\hlstd{]} \hlopt{-} \hlstd{yn_len, point[}\hlnum{2}\hlstd{]} \hlopt{+} \hlstd{xn_len)}
    \hlstd{)}

    \hlcom{# Return the reference points}
    \hlkwd{return}\hlstd{(ref_points)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Combine Catalog} \label{code:comb_ctg}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{comb_ctg} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{) \{}
    \hlstd{las} \hlkwb{<-} \hlkwd{readLAS}\hlstd{(x)}
    \hlkwa{if} \hlstd{(}\hlkwd{is.empty}\hlstd{(las)) \{}
        \hlkwd{return}\hlstd{(}\hlkwa{NULL}\hlstd{)}
    \hlstd{\}}
    \hlkwd{return}\hlstd{(las)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Compute Samples} \label{code:compute_samples}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{sample_lines} \hlkwb{<-} \hlkwd{c}\hlstd{()}
\hlstd{compute_samples} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{) \{}
    \hlkwa{if} \hlstd{(}\hlkwd{nrow}\hlstd{(x)} \hlopt{>} \hlnum{1}\hlstd{) \{}
        \hlstd{road_node} \hlkwb{<-} \hlkwd{st_coordinates}\hlstd{(x)}
        \hlstd{tot_len} \hlkwb{<-} \hlnum{0}
        \hlstd{len_inc} \hlkwb{<-} \hlnum{10}
        \hlstd{len_ofs} \hlkwb{<-} \hlstd{len_inc}
        \hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{2}\hlopt{:}\hlkwd{nrow}\hlstd{(road_node)} \hlopt{-} \hlnum{1}\hlstd{) \{}
            \hlstd{n1} \hlkwb{<-} \hlstd{road_node[i, ]}
            \hlstd{n2} \hlkwb{<-} \hlstd{road_node[i} \hlopt{+} \hlnum{1}\hlstd{, ]}

            \hlstd{len_seg} \hlkwb{<-} \hlkwd{euclidean_distance}\hlstd{(n1, n2)}
            \hlstd{len_ofs} \hlkwb{<-} \hlstd{len_ofs} \hlopt{+} \hlstd{len_inc}

            \hlkwa{while} \hlstd{(len_ofs} \hlopt{<=} \hlstd{tot_len} \hlopt{+} \hlstd{len_seg) \{}
                \hlstd{len_ofs} \hlkwb{<-} \hlstd{len_ofs} \hlopt{+} \hlstd{len_inc}

                \hlcom{# Add results to output vector}
                \hlstd{perp_segments} \hlkwb{<-} \hlkwd{calc_perp}\hlstd{(}
                    \hlstd{n1, n2,} \hlnum{30}\hlstd{,}
                    \hlstd{len_ofs} \hlopt{-} \hlstd{tot_len,}
                    \hlkwc{proportion} \hlstd{=} \hlnum{FALSE}
                \hlstd{)}

                \hlstd{multipoints} \hlkwb{<-} \hlkwd{st_multipoint}\hlstd{(}\hlkwd{matrix}\hlstd{(perp_segments,} \hlkwc{ncol} \hlstd{=} \hlnum{2}\hlstd{))}
                \hlstd{pts} \hlkwb{<-} \hlkwd{st_cast}\hlstd{(}\hlkwd{st_geometry}\hlstd{(multipoints),} \hlstr{"POINT"}\hlstd{)}
                \hlstd{n} \hlkwb{<-} \hlkwd{length}\hlstd{(pts)}

                \hlstd{pair} \hlkwb{<-} \hlkwd{st_combine}\hlstd{(}\hlkwd{c}\hlstd{(pts[}\hlnum{1}\hlstd{], pts[}\hlnum{2}\hlstd{], pts[}\hlnum{3}\hlstd{]))}
                \hlstd{linestring} \hlkwb{<-} \hlkwd{st_cast}\hlstd{(pair,} \hlstr{"LINESTRING"}\hlstd{)} \hlopt{%>%}
                    \hlkwd{st_buffer}\hlstd{(}\hlnum{2}\hlstd{)} \hlopt{%>%}
                    \hlkwd{st_sf}\hlstd{()} \hlopt{%>%}
                    \hlkwd{mutate}\hlstd{(}\hlkwc{road_id} \hlstd{=} \hlkwd{as.character}\hlstd{(}\hlkwd{unique}\hlstd{(x}\hlopt{$}\hlstd{road_id)))}
                \hlstd{sample_lines} \hlkwb{<-} \hlkwd{rbind}\hlstd{(sample_lines, linestring)}
            \hlstd{\}}
            \hlstd{tot_len} \hlkwb{<-} \hlstd{tot_len} \hlopt{+} \hlstd{len_seg}
        \hlstd{\}}
    \hlstd{\}}
    \hlkwd{return}\hlstd{(sample_lines)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Greyscale} \label{code:greyscale}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{greyscale} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{) \{}
    \hlstd{x} \hlkwb{<-} \hlstd{(x[[}\hlnum{1}\hlstd{]]} \hlopt{+} \hlstd{x[[}\hlnum{2}\hlstd{]]} \hlopt{+} \hlstd{x[[}\hlnum{3}\hlstd{]])} \hlopt{/} \hlnum{3}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Compute Linear Model} \label{code:lm_compute}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lm_compute} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{,} \hlkwc{f}\hlstd{)} \hlkwd{tryCatch}\hlstd{(\{}
        \hlstd{m} \hlkwb{<-} \hlkwd{lm}\hlstd{(}\hlkwc{formula} \hlstd{= f,} \hlkwc{data} \hlstd{= x)}

        \hlstd{p} \hlkwb{<-} \hlstd{m} \hlopt{%>%}
            \hlkwd{tidy}\hlstd{()} \hlopt{%>%}
            \hlstd{dplyr}\hlopt{::}\hlkwd{select}\hlstd{(}\hlkwc{p} \hlstd{= p.value)}

        \hlstd{pred_m} \hlkwb{<-} \hlkwd{predict}\hlstd{(m, x,} \hlkwc{type} \hlstd{=} \hlstr{"response"}\hlstd{)}

        \hlkwa{if} \hlstd{(}\hlkwd{sum}\hlstd{(p)} \hlopt{/} \hlkwd{nrow}\hlstd{(p)} \hlopt{<} \hlnum{0.05}\hlstd{) \{}
            \hlstd{x}\hlopt{$}\hlstd{lm} \hlkwb{<-} \hlstd{pred_m}
        \hlstd{\}} \hlkwa{else} \hlstd{\{}
            \hlstd{x}\hlopt{$}\hlstd{lm} \hlkwb{<-} \hlnum{NA}
        \hlstd{\}}

        \hlstd{x}\hlopt{$}\hlstd{lm_individual} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(x}\hlopt{$}\hlstd{lm} \hlopt{>} \hlkwd{quantile}\hlstd{(x}\hlopt{$}\hlstd{lm,} \hlnum{.95}\hlstd{),} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)}
        \hlstd{x}\hlopt{$}\hlstd{pred_lm_individual} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(x}\hlopt{$}\hlstd{lm} \hlopt{>} \hlkwd{quantile}\hlstd{(x}\hlopt{$}\hlstd{lm,} \hlnum{.95}\hlstd{),} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)}
        \hlstd{x}\hlopt{$}\hlstd{p_val} \hlkwb{<-} \hlkwd{sum}\hlstd{(p)}

        \hlkwd{return}\hlstd{(x)}
    \hlstd{\},} \hlkwc{error} \hlstd{=} \hlkwa{function}\hlstd{(}\hlkwc{e}\hlstd{)} \hlkwa{NULL}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{document}
